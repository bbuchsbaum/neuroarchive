---
title: "LNA Cookbook"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{LNA Cookbook}
  %\VignetteEngine{rmarkdown}
  %\VignetteEncoding{UTF-8}
---

This vignette demonstrates common workflows using the `neuroarchive`
package.

```r
library(neuroarchive)
```

## Quantisation and Lazy Reading

```r
# Create some example data
x <- array(rnorm(128), dim = c(4, 4, 4, 2))

# Write with quant transform
write_lna(x, "cookbook.h5", transforms = "quant")

# Open lazily and read a subset
r <- read_lna("cookbook.h5", lazy = TRUE)
r$subset(time_idx = 1)
subset_data <- r$data()
r$close()
```

## PCA Compression Pipeline

```r
# Use basis -> embed -> quant for PCA-based compression
pca_file <- "pca_example.h5"
write_lna(
  x,
  pca_file,
  transforms = c("basis", "embed", "quant"),
  transform_params = list(basis = list(k = 5))
)

# Validate the resulting file
validate_lna(pca_file)
```

### ROI and Time Slicing

```r
r <- read_lna(pca_file, lazy = TRUE)
roi <- array(runif(64) > 0.5, dim = c(4,4,4))
r$subset(roi_mask = roi, time_idx = 1:2)
roi_slice <- r$data()
r$close()
```

### Selecting Runs with Glob Patterns

```r
# Load multiple runs matching a pattern
handles <- read_lna(pca_file, run_id = "run-*", lazy = FALSE)
```

## Scaffolding a New Transform

```r
paths <- scaffold_transform("mycustom")
# After editing `paths$r_file` to implement the transform,
# it can be used like any built-in step:
# write_lna(x, "custom.h5", transforms = "mycustom")
```

This creates template files in `R/`, `inst/schemas/`, and `tests/` for a
new transform implementation.
